	\documentclass[journal,transmag]{IEEEtran}

\usepackage{cite}
\usepackage[pdftex]{graphicx}
% declare the path(s) where your graphic files are
\graphicspath{IMAGES/}
\DeclareGraphicsExtensions{.pdf,.jpeg,.png,.jpg}
\usepackage{amsmath}
\interdisplaylinepenalty=2500
\usepackage{algorithmic}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfon =sf]{subfig}
\usepackage{dblfloatfix}
\usepackage{url}
\usepackage{lipsum}
\usepackage{xcolor}
\usepackage{listings}


\lstset{
	escapeinside={/*@}{@*/},
	language=Java,	
	basicstyle=\fontsize{8.5}{12}\selectfont,
	numbers=left,
	numbersep=2pt,    
	xleftmargin=2pt,
	frame=tb,
	columns=fullflexible,
	showstringspaces=false,
	tabsize=4,
	keepspaces=true,
	showtabs=false,
	showspaces=false,
	morekeywords={inline,public,class,private,protected,struct},
	captionpos=b,
	lineskip=-0.4em,
	aboveskip=10pt,
	extendedchars=true,
	breaklines=true,
	prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
	keywordstyle=\color[rgb]{0,0,1},
	commentstyle=\color[rgb]{0.133,0.545,0.133},
	stringstyle=\color[rgb]{0.627,0.126,0.941},
}

% correct bad hyphenation here
\hyphenation{hy-phen}

\begin{document}
	
	\title{SET10108 Concurrent and Parallel Systems\\Report for Coursework Part 1}
	
	\author{\IEEEauthorblockN{Beej Persson, 40183743@live.napier.ac.uk}
		\IEEEauthorblockA{School of Computing,
			Edinburgh Napier University, Edinburgh}% <-this % stops an unwanted space
		
		\thanks{November 2017}}
	
	
	\markboth{40183743}{}
	% The only time the second header will appear is for the odd numbered pages after the title page when using the twoside option.
	
	\IEEEtitleabstractindextext{
		\begin{abstract}
			For part 1 of the coursework required for the SET10108 Concurrent and Parallel Systems module at Edinburgh Napier University a ray tracing algorithm's performance was to be evaluated and improved by utilising parallel techniques. This report documents one such investigation where the algorithm was parallelised and the difference in its	 performance was measured. 
		\end{abstract}
		
		\begin{IEEEkeywords}
			parallel, ray tracer, \textsc{OpenMP}, C++11, performance, speedup.
		\end{IEEEkeywords}}
	
	\maketitle
	
	\IEEEdisplaynontitleabstractindextext
	
	\IEEEpeerreviewmaketitle
	
	\section{Introduction and Background}
	\IEEEPARstart{T}{he} aim of this report is to evaluate the performance of a ray tracing algorithm and attempt to improve this performance using parallel techniques. The ray tracer initially processes sequentially on a single core of the CPU, but by investigating different parallel techniques the algorithm was changed to run on multiple threads in an attempt to increase the performance.
	
	\subsection{Ray Tracer}
	Ray tracing is a technique used to render an image where "a ray is cast through every pixel of the image, tracing the light coming from that direction" \cite{ray}. The path is traced from an imaginary eye through each pixel on a virtual image plane and the colour of the object visible through it is calculated. It is typically capable of producing visually realistic images of high quality but at a greater computational cost compared to typical rendering techniques. Therefore it tends to be used when an image can be generated slowly ahead of time, but isn't so well suited to the real-time rendering requirements of video games.
	
	\section{Initial Analysis}
	Initial analysis of the base-line performance of the application
	and likely places that can be parallelised. [5]
	
	The provided algorithm generates the image by iterating through each pixel using nested for loops. The ray tracer can also sample each pixel multiple times to produce a more accurate and detailed image but at the cost of processing time. Upon running the program a few times and changing the dimensions of the image produced and the number of samples per pixel an idea of its base-line performance was gathered.  By its nature of currently operating sequentially, increasing either the dimensions of the image produced or the number of samples per pixel increases the time it takes to produce the image with an almost perfect positive correlation. That is to say: doubling the size of the image produced or doubling the samples per pixel doubles the time taken.
	
	\lstinputlisting[caption = The many nested for loops of the ray tracer algorithm with the operations within the loops removed for clarity.]{./sourceCode/forloop.cpp}
	
	For smaller images at a low number of samples per pixel this results in reasonable times to produce an image, but when producing large images at a high number of samples per pixel the time to produce them was bottlenecked by only running sequentially on a single thread. Most of the time running the program is spent iterating through the nested for loops (seen in Listing 1) and so a clear solution to improving the performance of the algorithm is to run these for loops concurrently on multiple threads.
	
	
	\section{Methodology}
	Description and justification of the approach used and
	its overall suitability and rigour. [5]
	
	A systematic approach was undertaken to evaluate the performance of the algorithm and attempt to measure any improvements in performance gained by parallelising the algorithm.
	
	The first step was to run a series of tests on the provided sequential algorithm to provide a base-line that the performance of the different parallel techniques could be compared to. These tests were all done on the same hardware, the relevant specifications of which are shown in table \ref{hardware}. The dependent variable being measured was the amount of time it took for the algorithm to produce all the data in the pixel vector, which is used to generate the final image. The independent variables were the dimensions of the image and the number of samples per pixel. First the image size was kept constant at 256x256 whilst the number of samples per pixel was incremented, by powers of 2, from 4 up to 512. After this the samples per pixel was kept constant at 16 whilst the dimensions of the image were incremented, again by powers of 2, from 128x128 up to 1024x1024. For each change in the independent variables, 100 tests were run and the time it took for the algorithm to produce the data recorded, before the average run times were calculated. Further to this, 2 tests were run with a large image size of 1024x1024 and 1024 samples per pixel. This was only done twice due to how long it took for the algorithm to generate the image, but was still useful for comparison.
	
	\begin{table}[!t]
		\renewcommand{\arraystretch}{1.3}
		\caption{Hardware Specifications}
		\label{hardware}
		\centering
		\begin{tabular}{|l|l|}
			\hline
			Processor & i7-4790K 4 Core HT @ 4.00GHz\\ \hline
			RAM & 16.0GB\\ \hline
			OS & Windows 10 Pro 64-bit\\ \hline
		\end{tabular}
	\end{table}
	
	After these benchmarks for the sequential algorithm were recorded, a few different parallelising techniques were applied to the algorithm and tests were run to gain an idea of their performance. The techniques used were manual multi-threading and OpenMP.
	
	\subsection{Manual Multi-Threading}
	To parallelise the algorithm using manual multi-threading the set of for loops seen in Listing 1 were added to a single method which could then be run on multiple threads, as shown in Listing 2.
	
	\lstinputlisting[caption = The for loop used to run the forLoopAlgorithm method accross the required number of threads. The variables that are passed to the method are removed for clarity.]{./sourceCode/manualmulti-threading.cpp}
	
	\subsection{OpenMP}
	
	OpenMP is an API that supports shared-memory parallel programming and allows some additional manipulations on the code that were used to attempt to increase performance. The pre-processor argument shown in Listing 3 was used to parallelise the outer for loop, allowing the algorithm to be run across multiple threads.
	
	\lstinputlisting[caption = The OpenMP parallel for used to parallelise the shown for loop across the number of threads desired. The removed nested for loops can be seen in Listing 1.]{./sourceCode/omp.cpp}
	
	OpenMP's parallel for function comes with some options than can be used to change the way it spreads the workload across the threads.
	
	\section{Results and Discussion}
	Suitable performance analysis and testing documentation
	for the problem, including quality of presentation of
	the results. [10]
	
	\section{Conclusion}
	Level of discussion and appropriateness of the conclusions
	drawn based on the results gathered. [10]
	
	\begin{figure}[!h]
		\centering
		\includegraphics[width= 0.5\textwidth]{IMAGES/exampleImage}
		\caption{A Fucking Sad Frog.}
		\label{fig_frog}
	\end{figure}
	
	\begin{figure}[!h]
		\centering
		\includegraphics[width= 0.5\textwidth]{IMAGES/fig2}
		\caption{A Fucking Pupper.}
		\label{fig_pup}
	\end{figure}
	
	\section{Conclusion}
	The fucking conclusion goes here.
	
		{F}{uck}, this is a template for fucking IEEE transaction reports. \textsc{This bit of text is fucking different.} \LaTeX\ is dead, I don't think anyone actually uses it, and we are all being strung along on a terrible joke.
	
	\newpage
	
	\appendices
	\section{Proof of fucking something}
	Appendix one text goes fucking here.
	\lstinputlisting[caption = A fucking code listing.]{./sourceCode/hello.cpp}
	
	\section{}
	Fucking appendix two text goes here.
	
	\section*{Acknowledgement}
	The author would like to fucking thank...
	
	\bibliographystyle{IEEEtran}
	\bibliography{bibliography}
	
\end{document}